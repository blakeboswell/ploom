---
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# ploom

<!-- [CRAN_Status_Badge]() -->
<!-- [Build Status]() -->
<!-- [AppVeyor Build Status]() -->
<!-- [Coverage Status]() -->

# Overview

A collection of tools for out-of-memory linear model fitting and inference. Implements `lm` and `glm` analogs using Alan Miller's AS274 updating QR factorization algorithm. Collects and reports an array of pertinent fit statistics. Provides flexible and easy to use mechanisms to stream in data and stream out results during fitting.

> Currently in early development stage.

## tl;dr Features

> forthcoming

# Installation

```{r, eval = FALSE, message=FALSE}
# the early development version from GitHub:
# install.packages("devtools")
devtools::install_github("blakeboswell/ploom")
```

# Usage

```{r, eval = TRUE, include=FALSE}
library(ploom)
library(purrr)
```

## Model Initializing and Updating


### Linear Models

The `ploom` linear model, `oomlm`, is similar to base `lm` for fitting in-memory data.

```{r, eval = TRUE}
x <- oomlm(mpg ~ cyl + disp, data = mtcars)
```

Models are initalized with a call to `oomlm` and updated with `update`. The intended pattern is to initialize models without referencing data, then call `update` on each data chunk.

```{r, eval = TRUE}
# proxy for big data feed 
chunks  <- purrr::pmap(mtcars, list)

# initialize the model
x <- oomlm(mpg ~ cyl + disp)

# iteratively update model with data chunks
for(chunk in chunks) {
  x <- update(x, chunk)
}
```

We can avoid loops with functional patterns like `reduce`.

```{r, eval = TRUE}
x <- purrr::reduce(chunks, update, .init = oomlm(mpg ~ cyl + disp))
```

### Generalized Linear Models

The `ploom::oomglm` function fits generalized linear models via Iteratively Weighted Least Squares (IWLS).  

When fitting in-memory data the process is similar to `oomlm` but we use the function `reweight` instead of `update`.  `reweight` fits the model via iterative passes over the data until convergence.

```{r, eval = TRUE}
# initialize the model
x <- oomglm(mpg ~ cyl + disp)

# re-weight 8 times or until convergence
x <- reweight(x, mtcars, max_iter = 8)
```

When working with out-of-memory or chunked data, use the `oomfeed` object:

```{r, eval = TRUE}
# proxy for big data feed
chunks  <- purrr::pmap(mtcars, list)

# initialize the model
x <- oomglm(mpg ~ cyl + disp)

# iteratively reweight model over iterative calls to update
x <- reweight(x, oomfeed(mtcars, chunksize = 10), max_iter = 8)
```

The `reweight` process can also be implemented directly with `ploom` functions:

```{r, eval = TRUE}

x    <- oomglm(mpg ~ cyl + disp)
feed <- oomfeed(mtcars, chunksize = 10)

# a first pass over the data
x <- init_update(x)
x <- update(x, feed)
x <- end_update(x)
x

# a second pass over the data
x <- init_update(x)
x <- update(x, feed)
x <- end_update(x)
x
```

This is useful when debugging / evaluating  models with long runtimes by exposing the individual steps of the model process for inspection. 


## Using Feeds for a Variety of OOM Data Formats

```{r, eval = FALSE}

```


# Alternatives

> forthcoming

# Acknowledgements

> forthcoming