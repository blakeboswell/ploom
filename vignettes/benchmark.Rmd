---
title: "Benchmarking"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, eval = TRUE, warning = FALSE, message = FALSE,  echo = FALSE}
library(ggplot2)
library(ggrepel)
library(stringr)
library(dplyr)
```


```{r, eval = TRUE, echo = FALSE}

colors <- scale_color_viridis_d(option = "D")$palette(5)
colors <- c(colors[1], colors[rep(2:4, each = 2)])

plot_theme <- theme_minimal() +
  theme(
    plot.title = element_text(size = 18),
    legend.position = "none",
    legend.title = element_blank(),
    axis.title.y = element_blank(),
    axis.title.x = element_text(margin = margin(t = 20, r = 0, b = 10, l = 0)),
    axis.ticks = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank()
  )

x_format <- function(n) {
  as.character(n)
}

make_plot <- function(result, colors, selection, title) {
  
  N <- max(result$num_obs) / 10^6
  y_axis_limits <- c(min(result$mean), max(result$mean))
  
  df <- result %>%
    select(expression, min, mean, max, mem_alloc, num_obs) %>%
    dplyr::mutate(
      num_obs       = num_obs / 10^6,
      mem_alloc     = mem_alloc / 10^9,
      selected_fits = (expression %in% (names(colors)[selection]))
    )
  
  x <- df %>%
    filter(selected_fits) %>%
    rename(
      lower = min
      , upper = max
    )
  
  x %>%
    arrange(expression) %>%
    ggplot(aes(x = num_obs, y = mean, color = expression)) +
    geom_point(size = 3) +
    scale_y_continuous(
      breaks = seq(2, 100, 2),
      limits = y_axis_limits
    ) +
    scale_x_continuous(
      breaks = tail(seq(0, N, by = N / 5), 5),
      label  = x_format,
      limits = c(N * 1/5, N * 1.175)
    ) +
    geom_text(
      data = x %>% filter(num_obs == max(num_obs)),
      aes(label = expression, x = num_obs*1.025, y = mean),
      hjust  = 0
    ) +
    plot_theme +
    labs(
      title    = title,
      subtitle = "Seconds (mean)",
      x        = "Number of Observations (Million)",
      caption = "* Includes predict and residual calculation."
    ) +
    scale_color_manual(values = colors[selection])
  
}

```

## Purpose

This benchmark demonstrates that the bounded-memory fitting performed by ploom is at least as fast or faster than `lm()` and `glm()`. Fitting functions from the packages biglm and speedglm are also included for comparison.

## Scenario

The benchmark represents typical `lm()` and `glm()` fitting tasks.  The model being fit has 20 covariates and is fit to 1, 2, .., 5 million observations stored in a `tibble`.

## Results

> Although the runtimes are comparable, `oomlm()` is slightly faster than `lm()`.

```{r, eval = TRUE, echo = FALSE, fig.width=7, fig.height=4.2, fig.align='center'}

result <- readRDS(system.file("extdata", "lm_benchmark.Rds", package = "ploom"))

names(colors) <- c(
  "lm"
  , "oomlm"
  , "oomlm*"
  , "speedlm"
  , "speedlm*"
  , "biglm"
  , "biglm*"
)
colors[c("oomlm", "oomlm*")] <- "#E00F2E"
includes_resid <- c(T, F, T, F, T, F, T)

make_plot(
  result,
  colors,
  includes_resid,
  "Linear Model Runtime"
)

```

> `oomglm()` can be up to 2x faster than `glm()`.

```{r, eval = TRUE, echo = FALSE, fig.width=7, fig.height=4.2, fig.align='center'}

result <- readRDS(system.file("extdata", "glm_benchmark.Rds", package = "ploom"))

names(colors) <- c(
  "glm"
  , "oomglm"
  , "oomglm*"
  , "speedglm"
  , "speedglm*"
  , "bigglm"
  , "bigglm*"
)
colors[c("oomglm", "oomglm*")] <- "#E00F2E"
includes_resid <- c(T, F, T, F, T, F, T)

make_plot(
  result,
  colors,
  includes_resid,
  "Generalized Linear Model Runtime (Binomial Family)"
)

```

## Details

The benchmark is available for replication [here](https://github.com/blakeboswell/ploom/tree/master/benchmark).


<!-- Unlike `lm()` and `glm()`, fit functions from ploom, biglm, and speedglm do not calculate predictions and residuals by default. For parity, the benchmark run of these functions includes a call to `predict()` and a residual calculation. -->
