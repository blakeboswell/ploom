# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#'  Algorithm AS 274: Least Squares Routines to Supplement Those of Gentleman
#'  Author(s): Alan J. Miller
#'  Source: Journal of the Royal Statistical Society.
#'  Series Applied Statistics, Vol. 41, No. 2
#'  (1992), pp. 458-478
#'
#'  num_obs_
#'  the number of observations processed to date.
#'  
#'  num_params_ 
#'  the total number of dependent (x) variables,
#'  including one for the constant. In this version of the code,
#'  a constant or intercept term is always fitted.
#'
#'  rbar_dim_
#'  the dimension of the upper triangular matrix rbar_
#'  
#'  tol_set_
#'  a logical variable which is set when subroutine tolset() has
#'  been called to calculate tolerances for use in testing for
#'  singularities.
#'  
#'  rss_set_
#'  a logical variable indicating whether residual sums of squares
#'  are available and usable.
#'  
#'  D_
#'  array of row multipliers for the Cholesky factorization.
#'  The factorization is X = Q * sqrt(D) * R where Q is an ortho-
#'  normal matrix which is NOT stored, D is a diagonal matrix
#'  whose diagonal elements are stored in array d, and R is an
#'  upper-triangular matrix with 1's as its diagonal elements.
#'  
#'  thetab_
#'  vector of RHS projections (after scaling by sqrt(D)).
#'  Thus Q'y = sqrt(D) * Rhs
#'
#'  rbar_
#'  the upper-triangular matrix R.   The upper triangle only,
#'  excluding the implicit 1's on the diagonal, are stored by
#'  rows. This is where the R of the QR decomposition is maintained.
#'  R is also called the Orthogonal reduction in AS 75.1, or
#'  the Cholesky factorization.
#'
#'  tol_
#'  array of tolerances used in testing for singularities.
#'  
#'  rss_
#'  array of residual sums of squares, one for each Y variable.
#'  Rss[wycol][i] is the residual
#'  sum of squares with the first i variables in the model for the wycol-th
#'  y-variable.
#'            
#'  By changing the order of variables, the residual sums of
#'  squares can be found for all possible subsets of the variables.
#'
#'  The residual sum of squares with NO variables in the model,
#'  that is the total sum of squares of the first column of y-values, can be
#'  calculated as Rss[0][0] + D[0]*Rhs[0][0]^2.
#'  Since we always fit a constant, by itself Rss[0][0] is the sum of squares of
#'  (y - ybar) where ybar is the average value of y.
#'
#'  sserr_
#'  residual sum of squares with all of the variables included, one
#'  for each y-variable.
#'  
#' @keywords internal
NULL

